---
title: C++底层学习
date: 2024-04-20 12:08:06
tags:
categories:
- C++知识点
---

# 一、程序预编译-编译-链接-运行的过程

## 1.1 基础知识（操作系统相关）

### 1.1.1 可执行文件格式及数据

**1）Windows和Linux的可执行文件格式**

以C++为例，Windows下的可执行文件格式是`.exe`，格式为**PE**；Linux下的可执行文件是**ELF**格式。

**2）数据和指令的区别**

无论用什么语言编写的程序，最终都是一堆**二进制**数据，这些数据有两种类型：**指令**和**数据**。指令是CPU执行的，数据是CPU读写的。

其中**函数调用**、**循环**、**条件判断**等最终都会被编译成一系列的**指令**存在**文本段**，而**变量**、**常量**等则会被编译成**数据**存储在**数据段。

**3）文本段和数据段**

- **文本段**：存放程序的**指令**，是**只读**的，不允许写入。（代码区）
    - 静态成员函数、普通成员函数
- **数据段**：存放程序的**数据**，是**可读写**的。数据段又可以分为**数据段**和**BSS段**
    - **数据段**存放**初始化的全局变量**
    - **BSS段**存放**未初始化的全局变量**。

这些**段**组成了**可执行文件**，在程序运行时会被加载到进程的**虚拟内存**中，然后通过**页表**映射到**物理内存**中。

**4）虚拟地址空间**

前面提到**段**在程序运行时会被加载到**虚拟内存**中，当程序运行时，操作系统会为每个进程分配一个**虚拟地址空间**（Linux下是**4G**），其中**0-3G**是用户空间，**3-4G**是内核空间。

其中用户空间组成为（从低位到高位）：
- **预留空间**：`128M`
- **文本段.text**：存放程序的**指令**
- **数据段.data**：存放程序的**已初始化的数据**
- **BSS段.bss**：存放**未初始化的全局变量**
- **堆heap**
- **栈stack**

虚拟空间由**用户空间**和**内核空间**组成，因此**32位**系统下虚拟内存的最大空间为**3G+1G**，**64位系统是128T+128T**：

<img src="memory.png">

访问栈区的数据比访问堆区的数据快：
- 栈区数据直接由寄存器访问；堆区需要由指针访问，先将指针加载到寄存器，然后再访问数据
- 栈区可以利用连续空间的特性缓存数据；堆区数据是离散的，无法充分利用CPU缓存

### 1.1.2 CPU、寄存器、内存的关系

计算机的三个核心组成部分：**CPU**、**内存**、**I/O**。
- **CPU**：是计算机的大脑，属于高速设备，用来频繁地读取、执行指令（数据）。
- **内存**：属于中速设备，用来存储程序的指令和数据。
- **I/O**：属于低速设备，用来输入输出数据。

而**寄存器**是**CPU内部的**一块高速缓存，用来存储CPU执行指令时的临时数据，如**程序计数器**、**指令寄存器**、**通用寄存器**等。

一般来说，程序运行中会先从**内存**中读取指令到**寄存器**中，然后**CPU**执行这些指令，最后将结果通过**寄存器**写回到**内存**中。也就是说，**寄存器**是**CPU**和**内存**之间的桥梁。

## 1.2 生成可执行文件的过程

以Linux下的C程序为例，生成可执行文件的过程主要分为四个阶段：
- **预编译**（Preprocessing）->`.i`文件
- **编译**（Compilation）->`.s`文件
- **汇编**（Assembly）->`.o`文件
- **链接**（Linking）->可执行文件

<img src="Compiler_Work.png">

当我们有一个`.c`文件时，我们可以通过`gcc`命令将其编译成可执行文件:
```c
// hello.c
#include <stdio.h>
int main() {
    printf("Hello World!\n");
    return 0;
}
```
```shell
$ gcc hello.c # 编译
$ ./a.out # 执行
hello world!
```

而生成可执行文件过程就是`gcc`这个语句实现的，这句语句就实现了上述说到的4个步骤，接下来我们将剖析一下这四个步骤的具体实现。

### 1.2.1 预编译

预编译的主要工作是将**头文件以及宏定义替换成其真正的内容**，得到一个`.i`文件。所以预编译后得到的文件将比原文件大很多。

在Linux中我们可以通过`gcc -E`命令来分解编译过程，使其停留在预编译阶段，并通过`-o`指定文件名：

```shell
$ gcc -E hello.c -o hello.i
```

结果预编译后文件的大小变大，因为预编译后的文件中包含了很多头文件的内容：

|时间| 文件名 | 大小 | 代码行数 |
|:---:|:---:|:---:|:---:|
| 预处理前 | hello.c | 50 | 3 |
| 预处理后 | hello.i | 1.1K | 3 |

**C++中宏定义与函数的区别**

- **宏定义**在预编译阶段就完成了替换，相当于直接插入了代码，不存在函数调用，也没有返回值、不做类型检查、不加分号
- **函数**是在编译阶段才会被调用，有返回值、有类型检查、需要在最后加分号。


### 1.2.2 编译

编译的主要工作是将**预编译后的文件**转换成**汇编代码**，得到一个`.s`文件。

在Linux中我们可以通过`gcc -S`命令来分解编译过程，使其停留在编译阶段，并通过`-o`指定文件名：

```shell
$ gcc -S hello.i -o hello.s
```

最终得到的文件是一个汇编代码文件，内容如下：
```assembly
    .file	"hello.c"
    .text
    .globl	main
    .type	main, @function
main:
    .LFB0:
    .cfi_startproc
    pushq	%rbp
    .cfi_def_cfa_offset 16
    .cfi_offset 6, -16
    movq	%rsp, %rbp
    ......
```

### 1.2.3 汇编

汇编的主要工作是将**汇编代码**转换成**机器码Machine Code**（二进制），得到一个`.o`文件。

```shell
$ gcc -c hello.s -o hello.o
```

前面我们提到，可执行文件是由**文本段**和**数据段**组成的，其实每个`.o`文件就是一个**目标文件**，其中包含了**文本段**和**数据段**的内容。因此单独一个`.o`文件是无法运行的分布如下：

<img src="memory_o.png">

### 1.2.4 链接

假设我们代码不止一个文件，那么我们需要先将这些文件都全部生成为汇编代码`.o`，然后再将这些汇编代码链接成一个可执行文件`a.out`。

```shell
$ gcc hello.o hello2.o -o a.out
```

在链接的过程中，会将多个`.o`文件中的**文本段**和**数据段**合并成一个可执行文件，也就是将所有`.text`合并成一个`.text`，将所有`.data`合并成一个`.data`。最终的布局如下：

<img src="combine_o.png" width="80%">

### 1.2.5 运行

运行时会先将可执行文件`a.out`加载到**虚拟内存**中，然后通过**页表**映射到**物理内存**中，最终通过**CPU**执行这些指令。

## 1.3 静态链接和动态链接

静态链接和动态链接的主要区别在于**链接**的时机不同
- 静态链接是在**编译**时进行的
- 动态链接是在**运行**时进行的。

其库存储的**位置**不同
- 静态链接库是**编译**时链接集成到**可执行文件**中
- 动态链接库是作为独立的共享库存储的，**运行**时再加载到**内存**中。

### 1.3.1 静态链接

**静态链接**是指在**链接**阶段将程序中所有的**静态库**（如Linux下的`.a`文件、Windows下的`.lib`文件）都链接到可执行文件中，生成一个**独立的可执行文件**。

**1）优点**

静态链接的方式包含了程序运行需要的所有代码和数据，因此可以独立运行，不需要依赖其他文件。

**2）缺点**

每个使用该库的程序都会有一份该库的拷贝，因此会**占用更多的磁盘空间**。

同时，如果库文件更新了，那么所有使用该库的程序都需要重新编译，**维护成本高**。

### 1.3.2 动态链接

**动态链接**是指在**链接**阶段只将程序中的**引用**链接到可执行文件中，实际**链接**库是在**运行**时进行的，操作系统执行时会根据需要加载**共享库**（如Linux下的`.so`文件、Windows下的`.dll`文件）。

**1）优点**

由于多个程序运行时只需要一个共享库，因此**节省了磁盘空间**。

如果库文件更新了，只需要更新一份库文件，所有使用该库的程序都会**自动更新**。

**2）缺点**

程序运行时需要加载共享库，因此**启动速度慢**。

如果共享库出现问题（丢失或损坏），那么所有使用该库的程序都会受到影响。

> 参考：[C/C++编译链接](https://zhuanlan.zhihu.com/p/88255667)
> 参考：[C++：深入理解编译和链接过程](https://blog.csdn.net/Mr_H9527/article/details/81156112)

# 二、内存管理

## 2.1 C++内存分区

C++程序在运行时会将内存分为**5个区域**：

- **栈区**：存放**局部变量**等，由**系统自动**分配和释放。
- **堆区**：存放**动态分配**的内存，由**程序员**分配和释放。
- **全局/静态区**：存放**全局变量**和**静态变量**，程序启动时分配，程序结束时释放。
- **常量区**：存放**常量**，如字符串常量。
- **代码区**：存放**函数体的二进制代码**。

<img src="memory_fenpei.png" width="80%">

其实还有个**自由存储区**，也会被认为是**堆区**的一部分，用于存放**new**和**delete**的内存。

## 2.2 内存池

## 2.3 内存泄漏

内存泄漏在前面的博客中已经提到过：[C++基础知识学习](https://akirazheng.github.io/2024/03/09/C-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/)

内存泄漏主要是由**new**或**malloc**分配的内存没有被释放，长时间运行后如果内存满了会导致内存溢出、造成程序崩溃。建议通过**析构函数**、**智能指针**、**RAII**等方式来避免内存泄漏。

## 2.4 this指针

同样在前面的博客中也提到过：[C++基础知识学习](https://akirazheng.github.io/2024/03/09/C-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/)

主要注意的是它只能在类的**成员函数**中使用，且**静态成员函数**中不能使用。

## 2.5 类的内存分配

这部分包括类内的对齐在后面的**内存对齐**中会详细介绍。

# 三、内存对齐

内存对齐是编译器为了提高**内存访问效率**而采取的一种措施，能**减少内存访问次数**。

以32位系统为例，寄存器只能从能**被4整除的地址**（4bytes=32bits）中读取数据，因此如果数据不是4的整数倍，那么就需要**两次**内存访问才能读取完整的数据。

至于对齐字节是多少，这跟硬件的颗粒度有关，比如32位系统的寄存器是32bits，64位系统的寄存器是64bits。


## 3.1 内存对齐的好处

- **方便平台移植**
    - 某些硬件平台不能访问任意地址的内存，只能访问某些特定地址的内存，因此需要对齐来**兼容**这些硬件平台。
- **提高内存访问效率**
    - 未对齐的数据在内存中需要访问两次，而对齐的数据只需要访问一次，因此对齐能**提高内存访问效率**。（对于数据结构特别是栈，最好是在**自然边界**上对齐）

## 3.2 C++中结构体及类的内存对齐

**1）结构体的内存对齐**

C++中结构体的内存对齐是由**最宽基本类型**决定的，即结构体中的**每个成员**都要对齐到**最宽基本类型（结构体中变量类型最大值）**的整数倍。

- 对齐原则：
    - **确定对齐基准字节数**：找到结构体中**最宽的基本类型**，如最宽的是`double`，那么对齐基准字节数就是`8`。后面的数据都要按照`8`的整数倍对齐，不足的补0。
    - **整体对齐原则**：最后结构体的大小`sizeof(structA)`必须是**对齐基准字节数**的整数倍。

举例说明：
```c
struct structA {
    //最大的是int，因此对齐基准字节数是4，最终大小为12
    char a;  //a - - -
    int b;   //b b b b
    short c; //c c - -
};
```
```c
sizeof(structA);//12
```

优化后将`int`放在最前面或者最后面：
```c
struct structA {
    //最大的是int，因此对齐基准字节数是4，最终大小为8，放在末尾同理
    int b;   //b b b b
    char a;  //a - - -
    short c; //c c - -
};
```

**2）类的内存对齐**

- 如果是类中的成员变量，也是按照上述规则进行对齐
- 同时如果类中有**虚函数**，那么类中会有一个**虚函数表指针**，这个指针大小为**4**也要进行对齐。
- 类中的**成员函数**不占实例化对象内的空间，因为**成员函数**是**共享**的。
- 所以一个类中如果只有普通函数，没有任何变量，那么这个类的大小是**1**。（因为类的大小最小是**1**）
- **类中的static静态变量**也不占类的大小，因为**静态变量**是**共享**的。

```cpp
class A {
    //最大的是int，因此对齐基准字节数是4，最终大小为12
    int a;//a a a a
    char b;//b - - -
    virtual void func();//虚函数表指针:- - - -
};
```

```cpp
class A {
    void func();//成员函数不占空间
};
sizeof(A);//1
```

```cpp
class A {
    static int a;
};
sizeof(A);//1
```

**3）C++内存对齐最终还会再操作系统再次检查对齐**

比如我们在一个结构体中设置两个`char`型数据，那么根据C++的对齐规则，该结构体的大小是`2`，但是操作系统会再次检查对齐，如果操作系统要求对齐是`4`（32位），那么最终该结构体的大小是`4`（通过检查两个类对象的地址差发现的）。

```cpp
struct test2 {
	char a;
};
```

当用`sizeof`和通过地址差来检查对齐时，会发现`sizeof(test2)`是`2`，但是两个类对象的地址差是`4`。

```cpp
int main(){
    test2 t1;
    test2 t2;

    cout << sizeof(test2) << endl;//1
    cout << &t2<< endl;//000000D4769CF384
    cout << &t1<< endl;//000000D4769CF3A4
    //发现前后差了4，说明跟我们想象中的一个对象占用1个字节不一样，猜测操作系统也进行了对齐操作
    return 0;
}
```

# 四、内存池设计

## 4.1 C++默认的内存管理函数

### 4.1.1 系统分配内存空间

系统在接收到**内存分配请求**时，会有以下的操作：
- 查找**内存空闲表**
- 按照一定算法分配不小于申请需求的**内存块**
- 切割成合适的大小返回给用户
- 更新内存表
- 如果涉及多线程，由于多线程共享一块内存空间，所以还会统一进行**锁竞争**

那么就会存在**内存碎片**和**效率性能**的问题：

**1）内存碎片**

<img src="memory_sui.png">

- 由于**堆**上内存的分配和释放是程序员控制的、**不连续**的，所以会产生内存碎片，导致**内存利用率低**。
- 内存碎片又分为**外部碎片**和**内部碎片**
    - **外部碎片**是指已经被释放的内存，但是由于**大小不合适**无法分配给新的内存请求。
    - **内部碎片**是指**已分配的空间**如C++中的`new`分配的内存，由于**对齐**等原因导致的**浪费**。

**2）效率性能问题**

- 在多线程环境下，并发加锁会导致**性能下降**。
- 就像前面提到的系统分配内存的方式需要经过**查找**、**分配**、**更新**等操作，这些操作都会**消耗时间**，因此会影响**效率**。

所以需要引入**内存池**来**优化性能**以及减少**内存碎片**问题。

**内存池**是一种**预先分配**一定数量的内存，然后**按需分配**给用户，用户使用完后再**归还**给内存池，这样就可以**减少内存碎片**、**减少频繁地向系统申请和释放资源来提高效率**。

### 4.1.2 malloc内存分配机制

malloc分配内存有两种方式：`brk`和`mmap`
- malloc不是系统调用，由于使用了池化技术会从提前申请的内存中分配，所以**不会陷入内核态**
- `brk`和`mmap`是系统调用，会陷入内核态

**1）C++内存回收**

C/C++是编译型语言，**没有内存回收机制**，程序员需要自己释放不需要的内存。

C++中的内存管理方式主要有**运算操作符new**和**函数malloc**两种，其中**new**也是基于**malloc**实现的。所以我们这里主要讨论**malloc**。

在C++程序中进行内存回收的方式有**全局变量自动回收**、**delete、free回收**、**RAII通过析构函数自动回收**等方式

对于**堆**上的资源，由于上面提到的**效率**和**内存碎片**问题，C++不会直接向堆申请资源，而是借助**malloc**函数来向**系统**申请资源。

**2）malloc内存分配机制**

**malloc**属于**标准库用于接口操作层**，而用户调用**malloc接口**属于在**用户层**实现的，就像上面提到的，出于性能考虑，**malloc**是通过**内存池**的方式来管理内存的。

<img src="memory_malloc.png">

**malloc**的实现机制简单来说是，当我们申请一块如8B内存时，会实际上向**系统**申请一块更大的如1M内存，然后后面申请内存时都是从这1M内存中分配，当这1M内存不够时，再向系统申请1M内存。同时**malloc**内部还尝试通过**空闲链表**的设计方式来**减少内存碎片**。

其中最主要的分配内存思想是**分配时会搜索空闲链表，找到第一个大于等于所需空间的空闲区块**来进行分配，并根据**不同的编译器**具有不同的分配方式（一般不同编译器平台用的都是不同的内存分配算法）：
- 如windows下的采用的是微软的一套方案
- Linux下gcc用的**glibc**采用的内存分配器是**ptmalloc**

**malloc的优点：减少内存碎片**

malloc 只分配几种固定大小的内存块，可以减少外部碎片。

**malloc的缺点：多线程下性能问题**
- malloc的分配区有**互斥锁**来保证线程安全，但是进程中多个线程是**共享**一个malloc的分配区的，加锁的**时间代价**高。
- 由于需要查找合适的空闲区块，因此还有**查找**耗时的问题。

## 4.2 经典内存池的设计

### 4.2.1 设计思路

最基础的内存池设计类似于**malloc**的设计，主要包括**内存分配**和**内存释放**两个操作。操作是由**空闲链表**来实现的。

- 首先是提前向**OS**申请一块**大内存**，然后将这块内存均分成**小块**（后面优化可以分割成不同大小的内存块）
- 用链表表头`freeNodeHead`来存储**空闲内存块**，当用户申请内存时，就从`freeNodeHead`中取出一块内存块分配给用户
- 分割后的内存块通过链表组成**内存节点**
- 每次分配内存时从**空闲链表**中取出一个**头节点，时间复杂度为O(1)**
- 每次释放内存时将**内存节点**插入到**空闲链表**的**头部**，时间复杂度为O(1)
- 当空间不够用时，再向**OS**申请一块**大内存**

    <img src="memory_pool.png">

### 4.2.2 内存池的结构体设计

#### 1）变量

- 申请的内存块头指针：`pBlockHeader`
    - 内存池可以申请**多块内存**
- 上述每个内存块的**空闲链表**头指针：`pFreeNodeHead`
    - 每个内存块可以被分割成更小的内存
    - 每个内存块的**空闲链表**都是**独立**的
    
节点间的关系如下：

<img src="memory_pool.png">

#### 2）结构体

<img src="StructNode.png">

- **内存块结构体**：`MemoryBlock`
    - 包括**内存块**的**所有空闲节点**和**空闲链表**的**头指针**
    ```cpp
    struct MemoryBlock
    {
        MemBlock *pNext;
        FreeNode data[NumofObjects];
    };
    ```

- **空闲节点结构体**：`FreeNode`
    - 包括**空闲节点**的**数据**和**下一个空闲节点**的**指针**
    ```cpp
    struct FreeNode {
        FreeNode* pNext;
        char data[ObjectSize];
    };
    ```

## 4.3 tcmlloc内存池

tcmalloc 是 Google 开发的内存分配器，在**多线程**场景下性能表现比**malloc**更好。

主要表现在**tcmalloc**会为每个单独的线程申请一块**独享内存空间**，在线程级实现了缓存，使得用户在申请内存时大多情况下是**无锁内存分配**。

### 4.3.1 tcmalloc的架构

**tcmalloc**的架构在应用层由上至下主要包括：多个**Thread-cache线程缓存**、一个**Central-cache中央缓存**和一个**Page-cache页缓存**三部分。

<img src="tcmalloc.png">

- **Thread-cache线程缓存**：每个线程都有一个**线程缓存**，用于存储**小块内存**，线程在申请内存时优先从**线程缓存**中申请，如果**线程缓存**中没有内存，那么再从**中央缓存**中申请。
    - 由于**线程缓存**是**独享**的，因此**线程缓存**是**无锁**的。
- **Central-cache中央缓存**：用于存储**大块内存**，**线程缓存**中没有内存时会从**中央缓存**中申请。
    - **中央缓存**是**共享**的，因此需要**加锁**。
    - 但是**tcmalloc**设计中，用**哈希桶**来减少**锁竞争**，每个**哈希桶**对应一个**锁**，因此**锁竞争**的概率会降低。
- **Page-cache页缓存**：用于存储**大块内存**，**中央缓存**中没有内存时会从**页缓存**中申请。
    - **页缓存**是**共享**的，且为串行方式，每次仅有一个线程可以访问，因此**页缓存**是**有锁**的。

### 4.3.2 tcmalloc的性能优化

#### 1）效率优化

**查找时间优化**

为了减少**查找合适内存块的时间**，**tcmalloc**采用了**哈希桶**的方式来设计内存块的分割：

前面讲到分割一块**内存块**是**线性**的，而且首次分割是等值的。而**tcmalloc**通过**空间换时间**的方式，将**内存块**分割成**不同大小**的内存块，然后将这些内存块放到**哈希桶**中，这样在分配内存时就可以**直接按照对应大小找到合适的内存块**，而不需要**线性查找**。

这里大小不同是按照**2的幂次**来分割的，如`16`、`32`、`64`等。

<img src="hashCache.png">

**多线程竞争优化**

- **线程缓存**独享的无锁机制
- **中央缓存**采用**哈希桶**来减少**锁竞争**（多线程访问同一个哈希桶的概率降低）
- **加锁**使用更高效的**自旋锁**（自旋锁减少上下文切换、持锁时间短）

#### 2）减少内存碎片

`central cache`释放回一个span，则依次寻找`page cache`中span所管理的页号的前后页号的页有没有空闲，看是否可以**合并**，如果合并继续向前寻找。这样就可以将切小的内存合并收缩成大的span，减少内存碎片。

### 4.3.3 tcmalloc的缺点

**所需内存较大**的服务时，独享`Thread-cache`保守的小内存空间会失去意义，这种情况下当请求量上来，锁冲突严重，CPU使用率将指数暴增。

实际生成环境我们可以选择用**jemalloc**。


> 参考：[【项目】九万字手把手教你写高并发内存池（化简版tcmalloc）](https://blog.csdn.net/m0_62782700/article/details/135443352?spm=1001.2014.3001.5502)
> 参考：[C++ 内存池介绍与经典内存池的实现](https://blog.csdn.net/K346K346/article/details/49538975?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%2249538975%22%2C%22source%22%3A%22m0_46220956%22%7D)







